\title{\textbf{\Huge Book-taste clustering in goodreads communities}}

\author{{\Large Akanksha Tiwari (A0123476E)} \\
    {\Large Antoine Francois Pascal Creux (A0123427M)}\\
    {\Large Ashish Dandekar (A0123873A)} \\\\
    National University of Singapore,\\
    Singapore
}
\date{\today}

\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[english]{babel}
% \usepackage{listingstyle}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
% \usepackage{coz}
\usepackage{url}
\usepackage{array}
\usepackage{multirow}
% \usepackage[autolanguage]{numprint}

\begin{document}
%\maketitle


\section{Detailed Problem Description}
Goodreads is a website launched in early 2007, which lets ``people find and share the books they like and improve the process of reading and learning throughout the world.'' It is the world's largest site for readers and book recommendations with a user base of about 30 million members along with 34 million reviews from 900 million books as recorded in 2015 \cite{goodreads:aboutus}.

Goodreads provides a multitude of features to its users. It goes beyond the traditional rating and reviewing of books by allowing users to make friends and join and form reading groups based on their literary tastes.
Users can not only see what their friends have read, but they can also meet new people with similar reading interests. They can make recommendations to friends, follow authors, track the books they are currently reading, have read and want to read. In addition, goodreads provides personalized recommendations to book readers by analyzing the user data.\\

Basically, we want to detect and study goodreads communities based on books reviewing. Two people who has given similar rating for the same book share a similar interest, and thus are closed. We also want to improve this homophily by giving a negative score to different rating of the same novel.
We wonder if communities based on book tastes are analogous to friends communities, or what the average homophily score is between two friends?


\section{Related Work}


\section{Data Acquisition}

Goodread provides well documented and publically accessible API to query various features supported by the website. All we need is a developer key, which one gets after signing up on goodreads, and an OAuth access to use numerous APIs. The data of the users on a website, being the concern of privacy, is not readily available by means of goodread APIs. Aside from this a goodread user has liberty to keep his/her profile private making it accessible only to the friends on goodreads. Given the large userbase of goodreads, we hope to get sizeable dataset to run our analysis.\\\\
Althought the data scraping is laborious and time consuming, its is vital in our study. For a fair study, the data must be unbiased. The method which we use to gather the data may add some bias to it. So selection of scraping method is critical to data acquisition. There are two ways one can collect the data:
\begin{description}
\item[Retrieve User IDs from a group]
Goodreads hosts various reading groups catered to various genres and reading interests. User can become member of such groups or can initiate a group. In a group reading activities are supported wherein members can schedule the book readings so that they can share their opinions and conduct a healthy conversation. {\it Goodreads Authors/Readers} is one of the major groups on goodreads.  According to goodreads, this group is dedicated to connecting readers with goodreads authors. It is divided by genres, and includes folders for writing resources, book websites, videos/trailers, and blogs. \\
Goodreads provides an API to get the list of users given the ID of the group. One can get the ID of the group from the URL of the corresponding group on goodreads.
\item[Retrieve User IDs from reviews of books]
The list of various books genres is available at \ref{goodreads:genres}. One can select top rated books from the highly reviewed genres. So this collection of ``best-selling'' books forms a base set for the books. So we can get the list of users who have read these books. But goodreads fails to support an API which retrieves reviews for a particular book given its ID. Despite this, a meticulous analysis of \textit{Javascript} calls, the webpage makes to show the reviews of a book to the user, reveals a bacdoor API \textit{book/reviews/}. We can retrieve user realted information User ID and the rating by parsing the response to the \textit{Javascript} callback using regular expressions.
\end{description}
The list of User IDs thus scraped serve as a base user set. We later collect {\it 1-neighbourhood} of this set of users, namely friends of them and the books read by these friends, to get a substantial dataset.  \\
We have decided to go with the first strategy. By scraping a toy dataset, we observe the data to be unbiased. Plus the data related to the friends assures the sizeable amount for the analysis.

\section{Description of the method}
% \section{Description of the method, algorithm, and/or method that is/are at the core of your project}


\section{Discussion of project progress}
\subsection{Data Collection}
Table \ref{crawl_stat} shows the statistic of the group {\it Goodreads Authors/Users}. As stated earlier, it has been observed that many users have kept their profiles private. The users who have not reviewed a single book are of no use for the analysis. So, filtering these users leaves behind a base user set with size close to 8000.
\begin{table}[h]
\begin{center}
\begin{tabular}{cc}
\hline
\#Ratings                  & 567461 \\ \hline
\#Public Profiles          & 7815   \\ \hline
\#Private Profiles         & 2564   \\ \hline
\#Profiles w/o any reviews & 7203   \\ \hline
\end{tabular}
\label{crawl_stat}
\caption{Goodreads Authors/Users Statistics}
\end{center}
\end{table}
To gather a substantial set of users, we collect the friends of the base users. Again, we filter the friends who are already in the group, who have kept their profiles private and the ones who have not reviewd a single book. Following this strategy, we have a consolidated list of 95503 users which will be the user base for out analysis. \\
The code for scraping is available at {\it https://github.com/acreux/nus-cs5345-project/tree/dev}. For d
\subsection{Data processing}


\subsection{Algorithm}

We focus on the study of communities detection based on the user graph we have generated.

The most common 

Community detection is a widely discussed topic in the social networking literature\footnote{Social networks are generally sparse networks. When the networks are dense, the community detection does not seem to be a wise option. The dense networks possess large number of inter-community edges which yield poor partitioning. For dense networks, discrete data analysis techniques are used.}\cite{clauset}.

Based on the sample we have, the graph is very dense.
With less than 8000 nodes, we have more than 16 million edges. The density is about ???.

Based on \cite{mining_massive_dataset}, we wanted to test which community detection algorithm could be used.
At first, we were supposed to use the Girvan-Newman algorithm as it was the most common community detection algorithm\cite{newman}.
The Girvanâ€“Newman algorithm uses an ``edge betweenness'' of an edge as the number of shortest paths between pairs of nodes that run along it.
Edges with high betweeness are very likeyly the connection between communities.
Thus, removing the edges in the decreasing order of between should reveal the dendogram associated, and thus the communities.
This compute takes $O(ne)$ running time, and thus is too long for our graph.\\

G-N can be limiting as any node has to be placed in one unique community.
Since, we deal with a bipartite graph, we can we may try to find complete bipartite subgraphs.
That means we can split the users and the books into two distinct sets respectively, such as $users0$ and $books0$, and $users1$ and $books1$ are linked, but no edge relate $users0$ and $books1$, or $users1$ and $books0$.
Based on our graph density which is pretty high, we cannot apply this algorithm: we would a unique complete clique.
However, we may filter the edges by for instance, keeping only the edges with a rating of 5.\\

The Simrank method, where a random walker starts at one node, and is allowed to go through the edges is cannot also be applied to our dense graph.
The similarity between each node is too time-consuming. 

% There is no universally accepted definition of community since the idea of community is pertinent to the underlying network.
% The general picture of community detection algorithm relies on the quality function which defines the quality of the cluster.
% Algorithms aim at either maximizing or minimizing (depends on the way quality function has been defined) cumulative quality of the network.
% Generally, the quality function for a community is defined to be the difference between intra-community edges and inter-community edges.

% There are different classes of community detection algorithms.
% Graph partitioning algorithms return two partitions of the network using techniques like max-flow min-cut, conductance, etc.
% Despite their scalability, these algorithms require the analyst to have some idea about the groups in the network beforehand.
% So they are not good for the exploration of the groups in the community.
% Similarly, partition clustering algorithms, like k-means clustering, need analyst conjecture about the existence of clusters.
% These algorithms also require the graph to be embedded in the metric space to quantify the notion of the distance.
% Spectral clustering algorithms require eigenvalue decomposition of the network graph which is prohibitive for massive networks.
% Hierarchical partitioning techniques, comprising of agglomerative and divisive partitioning methods, are good for exploratory analysis.
% Agglomerative clustering techniques are computationally expensive. Divisive algorithms are top-down partitioning techniques which go on deleting edges one by one which causes formation of communities. Girvan-Newman algorithm is one of the most popular divisive community detection algorithm which we propose to use for detecting user communities in goodreads.

% \section{Project plan for remaining/unfinished work items}

% To capture the notion of similar interest among the users of goodreads  the concept of one-mode analyses of bipartite network data(also known as affiliation network in sociology terminology) can be used \cite{wasserman}. Such analyses use matrices derived from the affiliation matrix, $\mathcal{A}$, wherein actors are represented in rows and the events are represented in columns.

% Co-membership of actors $i$ and $j$ for an event $k$ is identified if the rows $a_i$ and $a_j$ both have 1 in the column $k$ .
% Hence,  $a_{ik}~=~1$ and $a_{jk}~=~1$ indicates that both actors participated in the event $k$. So, the total number of co-memberships for the two actors can be computed from the number of times that $a_{ik}~=~1$ and $a_{jk}~=~1$ where $k$ takes all possible values. The number of events with which both actors $i$ and $j$ are associated will vary from 0 (if both have no affiliated events in common) to $h$(if both have all affiliated events in common).\\

% \section{Problem Description}
% In this project, we aim to probe the groups of users within goodreads based on their reading interests. As stated earlier, goodreads is more than just a book reviewing website. Users and authors on goodreads can connect amongst themselves forming a rich social network. We do not want to observe the groups/clusters within such a social network, which already exists in goodreads, since this network may not necessarily capture the reading interests of the users in it. We will use the information about the books read by the users and ratings given by them to capture the ties amongst the users.\\

% In this section, we only focus on the book read by two users. Let $U$ be the set of users and $B$ the set of books on goodreads. We will construct an undirected bipartite graph $G(V, E)$ using these two sets where $V ~=~ U \cup B$ and $E~=~U \times B$. An edge exists between a vertex $u_i \in U$ and a vertex $b_k \in B$ if a user $u_i$ has read book $b_k$.\\\\
% We consider the rating given by a user $u_i$ to a book $b_k$ to assign weight to the edge between them. The weight to this edge plays an important role in the semantics of the network. Consider a scenario wherein a book $b_k$ is read by both the users $u_i$ and $u_j$. Suppose user $u_i$ has liked the book and hence has positively rated the book whereas user $u_j$ has not liked the book and so has given a low rating to the book. If we do not take this fact into the account, then these users might end up being placed in a same reading group. So as to prevent this situation, we assign weight to the edges in $G$. Let $r_{ik}$ be the rating given by user $u_i$ to book $b_k$. Let $w \rightarrow E \times \{1, -1\}$ be the weight function.\\
% $\forall (i, k) \in E$, 
% \[
%     w(i, k) = \left\{\def\arraystretch{1.2}%
%         \begin{array}{@{}c@{\quad}l@{}}
%         1 & r_{ik} \geq \alpha\\
%         -1 & r_{ik} < \alpha\\
%         \end{array}\right.
% \]
% where $\alpha$ is some threshold which can be tuned during the experimentation.\\
% A similar study can be conducted based on the author $a_k \in A$ or the group membership $g_k \in H$, for instance:\\
% $\forall (i, k) \in F=U \times H$, 
% \[
%     w(i, k) = \left\{\def\arraystretch{1.2}%
%         \begin{array}{@{}c@{\quad}l@{}}
%         1 & u_i \in g_k\\
%         0 & u_i \notin g_k\\
%         \end{array}\right.
% \]
% \\

% Let $\mathcal{M}$ be a $|U| \times |B|$ matrix which represents the underlying graph $G$. If there exists an edge between user $u_i$ and book $b_k$ then $\mathcal{M}_{ik}^{th}$ entry in the matrix is set to the weight of the corresponding edge otherwise the entry is set to zero. We obtain $\mathcal{U}$, matrix encoding the relationship amongst the users, using $\mathcal{M}$ by calculating $\mathcal{M}\mathcal{M}^{T}$. The graph encoded by $\mathcal{U}$ is the graph of the interest for finding the user groups. We propose to explore the interesting user groups by using graph partitioning algorithms like Girvan-Newman algorithm.


% \section{Underlying Assumptions}

% Goodreads data set is not available online and we will have to acquire all the data through their APIs. Hence, as of now, it is not feasible to state appropriate assumptions since we do not have an exact picture of the data. Once we have obtained all the data we will update this section.

% \section{Data acquisition}
% \label{sec:data_acquisition}
% Goodreads data is not available online, we have to acquire all data through their APIs. Stanford students have already studied the Goodreads platform by building a product recommendation system for it\cite{stanford:goodreads}. They acquired data through the \textit{book.shelves} API method. Given a \textit{user\_id} and a bookshelf name, they were able to query all the books a user may have put in this virtual bookshelf. The major issue is that goodreads does not list every user\_id. So, they decided to query for user\_id randomly to query the books people have put in their public â€˜reading' shelves. They gathered data for 4000 users and their `'reading books'.

% We have decided to query the data using other APIs, available at \cite{goodreads:api}:
% \begin{itemize}
% \item group.list - List groups for a given user
% \item group.members - Return members of a particular group
% \item group.show - Get info about a group
% \item fanship.show - Show author fan ship information
% \item owned\_books.list - List books owned by a user
% \item shelves.list - Get shelves owned by a user
% \item user.show - Get shelves owned by a user
% \item user.followers - Get user's followers
% \item user.following - Get people a user is following
% \item user.friends - Get people a user is following
% \end{itemize}

% Through these APIs we get information related to the network of a user such as :
% \begin{itemize}
% \item the users followed by a user and the users who follow him (similar to twitter)
% \item the reading groups joined by a user
% \item the authors who's fan the user is
% \item the books stored in the shelves of a user
% \item all the friends of a user
% \end{itemize}

% Goodreads has 30 million users which may be too large for our study, but the goal is to gather an acceptable amount of data. Goodreads provides the top users in certain categories such as the top 50 active users, top 50 readers, top 50 most popular reviewers as well as the best reviews. These statistics are computed for the last week, last month, last 12 months and all the time for each country (as well as worldwide).
% Based on the top users, we will have a list of user\_id from which we can query the data. On the other hand, for each user, we will store the books read and stored on the shelves, the authors the user is a fan of and the groups the user belongs to.\
% Also, we  can only query a user data if the profile is public. Based on our initial investigation, most profiles are public and thus this  should not be an issue. However, we will store the information that a user profile is private as well.

% \section{Project Objectives}


% \begin{itemize}
% \item Gather relevant data (as mentioned in \ref{sec:data_acquisition} from goodreads
% \item Implement algorithms for community detection on the graphs generated from the data
% \item Analyze and interpret the results of applying these algorithms on the data
% \item Compare the communities detected by our work with the actual groups present on goodreads
% \item Study the effect of recommendations and users' friend on his/her choice of books (If time permits)
% \end{itemize}

% % http://networkx.github.io/documentation/networkx-1.9.1/reference/generated/networkx.algorithms.cluster.clustering.html?highlight=clustering#networkx.algorithms.cluster.clustering

% % http://jponnela.com/web_documents/a9.pdf     network x clustering algo

% % Girvan-Newman algo
% % https://en.wikipedia.org/wiki/Girvan%E2%80%93Newman_algorithm

% % Graph tool algo
% % http://graph-tool.skewed.de/static/doc/clustering.html

% % Clustering Stanford
% % http://web.stanford.edu/class/cs345a/slides/12-clustering.pdf

% % Stanford goodreads
% % http://cs229.stanford.edu/proj2008/IsaacsonSebastian-GoodReadsRecommendations.pdf


% \section{Proposed Contributions}
% As of the literature survey done up to now, there has not been a study on the detection of communities of readers with similar reading interests on goodreads dataset.
% This work will aim to identify such communities using algorithms for community detection such as Girvan-Newman algorithm and compare the communities detected with the already formed groups on goodreads and analyze how different or similar they are.
% This would give us insights into whether the friendship and groups formed on goodreads are based on reading interests or there are other factors that come into play. It can be especially useful to authors in identifying the right target audience for their work.

% In addition, if we get time, we can also look at how the recommendations and friendships in the goodreads' user network affect the choice of books. This information can be used by goodreads themselves to improve their recommendation engine.

% \section{Success Measures}

% Our entire work depends on acquiring the data in a short amount of time. We consider we validate this part if we manage to gather at least one million users with all their features (friends, books owned, followers, users following\dots) stored.\\
% Then, we will evaluate our clustering algorithm by studying by hand the communities formed. We expect to see communities gathered around common literature tastes such as science-fiction, romance or detective novels. 


% \section{Project Plan}
% \begin{itemize}
% \item Week 0 - Identifying the project area, datasets to work on and conducting literature review.
% \item Week 1 -  Collecting the data from the various goodreads APIs as mentioned above.
% \item Week 2 -  Data cleaning, formulating assumptions based on the data and modifying the project objectives accordingly. These changes will be reflected in the Project Milestone report.
% \item Week 3 \& Week 4 - Implementing the community detection algorithms on the data and analyzing the results.
% \item Week 5 - Interpretation and documentation of the results
% \end{itemize}
% \section{Deliverables}

% The deliverables will be composed of a commented and tested code that will:
% \begin{itemize}
% \item Query the Goodreads API
% \item Store the data in a database
% \item Implement the community clustering
% \item Apply the algorithm to goodreads data
% \end{itemize}

% Also, thorough analysis an of the results of the algorithm will be conducted through comments and illustrations.

\newpage

\bibliographystyle{abbrv}
\bibliography{ref}
\end{document}
