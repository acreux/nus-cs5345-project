\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[english]{babel}
% \usepackage{listingstyle}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
% \usepackage{coz}
\usepackage{url}
\usepackage{array}
\usepackage{multirow}
\usepackage[autolanguage]{numprint}


\title{\textbf{CS5232 Project Proposal\\} }
\author{Antoine Francois Pascal Creux (A0123427M)}
\date{March 18th, 2014}

\begin{document}
\maketitle


\section{Concept Study}
Goodreads is a website launched in early 2007, which lets ``people find and share the books they like and improve the process of reading and learning throughout the world.'' It is the worldâ€™s largest site for readers and book recommendations with a user base of about  30 million members along with 34 million reviews from 900 million books as recorded in 2015\cite{goodreads:aboutus}.

Goodreads provides a multitude of features to its users. It goes beyond the traditional rating and reviewing of books by allowing users to make friends and join and form reading groups based on their literary tastes. Users can not only see what their friends have read, but they can also meet new people with similar reading interests. They can make recommendations to friends , follow authors, track the books they are currently reading, have read and want to read. In addition, goodreads provides personalized recommendations to book readers by analyzing the user data. \\\\

To capture the notion of similar interest among the users of goodreads  the concept of one-mode analyses of bipartite network data(also known as affiliation network in sociology terminology) can be used \cite{wasserman}.Such analyses use matrices derived from the affiliation matrix, $\mathcal{A}$, wherein actors are represented in rows and the events are represented in columns.\\

Co-membership of actors $i$ and $j$ for an event $k$ is identified if the rows $a_i$ and $a_j$ both have non-zero entries in the column $k$ . So, the total number of co-memberships for the two actors can be computed by summing over all possible events for the respective actors. Such a one mode analyses reduces to the multiplication $\mathcal{A}\mathcal{A}^{T}$. We want to explore communities in the graph obtained in this way.\\\\

Community detection is widely discussed topic in the social networking literature\footnote{Social networks are generally sparse networks. When the networks are dense, the community detection does not seem to be the wise option. The dense networks possess large number of inter-community edges which yields poor partitioning. For dense networks, discrete data analysis techniques are used.}. There is no universally accepted definition of community as the idea of community is pertinent to the underlying network. The general picture of community detection algorithm relies on the quality function which defines the quality of the cluster. The algorithm aims at either maximizing or minimizing(depends on the way quality function has been defined) cumulative quality of the network. Generally the quality function for a community is defined to be the difference between intra-community edges and inter-community edges. \\\\

There are different classes of community detection algorithms. Graph partitioning algorithms return two partitions of the network using techniques like max flow min cut, conductance, etc. Despite their scalability, these algorithms require the analyst to have some idea about the groups in the network beforehand. So they are not good for the exploration of the groups in the community. Similarly partition clustering algorithms, like k-means clustering, needs analyst conjecture about the existence of clusters. These algorithms also require the graph to be embedded in the metric space to quantify the notion of the distance. Spectral clustering algorithms reuqire eigenvalue decomposition of the network graph which is prohibitive for massive networks. Hierarchical partitioning techniques, comprising of agglomerative and divisive partitioning methods, are good for the exploratory analysis. Agglomerative clustering techniques are computationally expensive. Divisive algorithms are top-down partitioning techniques which goes on deleting edges one by one which causes formation of communities. Girvan-Newman algorithm is one of the popular divisive community detection algorithm which we poropose to use for detecting user communities in goodreads.

\section{Problem Description}
In this project, we aim to probe the groups of users within goodreads based on their reading interests. As stated earlier, goodreads is more than just a book reviewing website. Users and authors on goodreads can connect amongst themselves forming a rich social network. We do not want to observe the groups/clusters within such a social network, which already exists in goodreads, since this network may not necessarily capture the reading interests of the users in it. We use the information about the books to capture the ties amongst the users. \\\\
Let $U$ and $B$ be the set of users and the set of books on goodreads respectively. We will construct an undirected bipartite graph $G(V, E)$ using these two sets where $V ~=~ U \cup B$. An edge exists betweem a vertex $u_i \in U$ and a vertex $b_j \in B$ if a user $u_i$ has read book $b_j$.\\\\
We consider the rating given by a user $u_i$ to a book $b_j$ to assign weight to the edge between them. The weight to this edge plays an important role in the semantics of the networks. Consider a scenario wherein a book $b_k$ is read by both the users $u_i$ and $u_j$. Suppose user $u_i$ has liked the book and hence has positively rated the book whereas user $u_j$ has not liked the book and so has given a low rating to the book. If we do not take this fact into the account then these users might end up being placed in a same reading group. So as to prevent situation, we assign weight to the edges in $G$. Let $r_{ij}$ be the rating given by user $u_i$ to book $b_j$. Let $w \rightarrow E \times \{1, -1\}$ be the weight function. For every $(i, j) \in E$, 
\[
	w((i, j)) = \left\{\def\arraystretch{1.2}%
		\begin{array}{@{}c@{\quad}l@{}}
		1 & r_{ij} \geq \alpha\\
		-1 & r_{ij} < \alpha\\
		\end{array}\right.
\]
where $\alpha$ is some threshold which can be tuned during the experimentation.
\\\\
Let $\mathcal{M}$ be a $|U| \times |B|$ matrix which represents the underlying graph $G$. If there exists an edge between user $u_i$ and book $b_j$ then $\mathcal{M}_{ij}^{th}$ entry in the matrix is set to the weight of the corresponding edge otherwise the entry is set to zero. We obtain $\mathcal{U}$, matrix encoding the relationship amongst the users, using $\mathcal{M}$ by calculating $\mathcal{M}\mathcal{M}^{T}$. The graph encoded by $\mathcal{U}$ is the graph of the interest for finding the user groups. We propose to explore the interesting user groups by using graph partitioning algorithms like Girvan-Newman algorithm.
\section{Underlying Assumptions}
\section{Data acquisition}

Goodreads data is not available online, we have to acquire all data through their APIs. Stanford students have already studied Goodreads platform by building a product recommendation. \cite{stanford:goodreads}. However, they have not published the data they acquired and we think that their data acquisition is wrongly implemented based on erroneous assumptions. Indeed, they acquired data through the \textit{book.shelves} api method. Given a \textit{user\_id} and a bookshelf name, they were able to query all the books a user may have put in this virtual bookshelf. The major issue is that goodreads do not list every user\_id. They then decided to query for user\_id randomly to query the books people have put to their public `reading' shelve. Finally, they only gather 4000 users and their `reading books'.

We have decided to query the data using other APIs, available at \cite{goodreads:api}:
\begin{itemize}
\item group.list - List groups for a given user
\item group.members - Return members of a particular group
\item group.show - Get info about a group
\item fanship.show - Show author fanship information
\item owned\_books.list - List books owned by a user
\item shelves.list - Get shelves owned by a user
\item user.show - Get shelves owned by a user
\item user.followers - Get user's followers

Here, we see we can add many kinds of information related to the network of a user:
\begin{itemize}
\item such as in Twitter, a user can follow other users, and can be followed
\item a user can take part in reading groups
\item a user can be fan of an author
\item we have all books stored in all shelves of a use
\end{itemize}

Goodreads have 30 million users which may be too large for our study, but the goal is to gather an acceptable amount of data. Goodreads provide the top user in certain categories such as the top 50 active users, top 50 readers, top 50 most popular reviewers well as the best reviews. These statistics are computed for the last week, last month, last 12 months and all the time for each country( as well as worldwide).
Based on the top users, we have a list of user\_id from which we can query the data. On the other hand, for each user, we will store the books read and stored on the shelves, the authors the user is fan of and the groups the user belongs to.\
Finally, we only can query a user data if the profile is public. Based on our first study, most profile are public and thus should not raise an issue. Even so, we will store the information that a user profile is private.


\section{Project Objectives}

\section{Literature review}

We compare n methods for the clustering of our dataset. We give a brief summary of the different clustering methods and state if these methods will be scalable to our own dataset.

Quantitatively, clustering aims at assigning each data point to a cluster.



\subsection{Hierarchical Clustering}
Hierarchical clustering builds a hierarchy of clusters, Either it is built \emph{bottom up}, as we start with the same numbers of clusters and data points, and we try to group clusters with each other. The \emph{top down} us the opposite: we start with a unique cluster that we are going to split recursevely.\\

Complexity is very high ($\Theta$($n^3$)), and thus is not pertinent to big datasets, even if heuristics lower the complexity to ($\Theta$($n^2$).




\subsection{K-Means Clustering}

K-means clustering aims at computing k clusters from that will minimize the distance from the data points to the cluster, such as we will split n data points into k groups. It is a centroid-based clustering, and does not apply only to graphs.
The most common application of k-means clustering is the iterative algorithm named Lloyd's algorithm.
The major issue is that we have to set in advance the number of clusters we want to 

\begin{enumerate}
\item Initialize (randomly preferably) the center of the k clusters
\item For each point, assign to it the closest cluster
\item Compute the new position of every cluster as the center of all data points assigned to this cluster
\item Repeat 2 and 3 until the clusters do not move (Relative to a $\epsilon$ for instance)
\end{enumerate}


% http://networkx.github.io/documentation/networkx-1.9.1/reference/generated/networkx.algorithms.cluster.clustering.html?highlight=clustering#networkx.algorithms.cluster.clustering

% http://jponnela.com/web_documents/a9.pdf     network x clustering algo

% Girvan-Newman algo
% https://en.wikipedia.org/wiki/Girvan%E2%80%93Newman_algorithm

% Graph tool algo
% http://graph-tool.skewed.de/static/doc/clustering.html

% Clustering Stanford
% http://web.stanford.edu/class/cs345a/slides/12-clustering.pdf

% Stanford goodreads
% http://cs229.stanford.edu/proj2008/IsaacsonSebastian-GoodReadsRecommendations.pdf

\section{Proposed Contributions}
As of the literature survey done upto now there has not been a study on the detection of communities of readers with similar reading interests on goodreads dataset. This work will aim to identify such communities using algorithms for community detection such as Girvan-Newman algorithm and compare the communities detected with the already formed groups on goodreads and analyse how different or similar they are. This would give us insights into whether the friendship and groups formed on goodreads are based on reading intersts or there are other factors that come into play.It be especially useful to authors in identifying the right target audience for their work.

In addition, if we get time we can also look at how the recommendations and friendships in the goodreads' user network affects their choice of books. This information can be used by gooddreads themselves to improve their recommendation engine.
\section{Success Measures}
\section{Project Plan}
Week 0 - Identifying the project area, datasets to work on and conducting literature review.
Week 1 -  Collecting the data from the various goodreads APIs as mentioned above.
Week 2 -  Data cleaning, formulating assumptions based on the data and modifying the project objectives accordingly. These changes will be reflected in the Project Milestone report.
Week 3 and Week 4 - Implementing the community detection algorithms on the data and analysing the results.
Week 5 - Interpretation and documentation of the results 
\section{Deliverables}


\bibliographystyle{abbrv}
\bibliography{references}
\end{document}
