\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[english]{babel}
% \usepackage{listingstyle}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
% \usepackage{coz}
\usepackage{url}
\usepackage{array}
\usepackage{multirow}
% \usepackage[autolanguage]{numprint}


\title{\textbf{CS5232 Project Proposal\\} }
\author{Antoine Francois Pascal Creux (A0123427M)}
\date{March 18th, 2014}

\begin{document}
\maketitle


\section{Concept Study}
Goodreads is a website launched in early 2007, which lets ``people find and share the books they like and improve the process of reading and learning throughout the world.'' It is the worldâ€™s largest site for readers and book recommendations with a user base of about  30 million members along with 34 million reviews from 900 million books as recorded in 2015 \cite{goodreads:aboutus}.

Goodreads provides a multitude of features to its users. It goes beyond the traditional rating and reviewing of books by allowing users to make friends and join and form reading groups based on their literary tastes. Users can not only see what their friends have read, but they can also meet new people with similar reading interests. They can make recommendations to friends , follow authors, track the books they are currently reading, have read and want to read. In addition, goodreads provides personalized recommendations to book readers by analyzing the user data. \\\\

To capture the notion of similar interest among the users of goodreads  the concept of one-mode analyses of bipartite network data(also known as affiliation network in sociology terminology) can be used \cite{wasserman}. Such analyses use matrices derived from the affiliation matrix, $\mathcal{A}$, wherein actors are represented in rows and the events are represented in columns.\\

Co-membership of actors $i$ and $j$ for an event $k$ is identified if the rows $a_i$ and $a_j$ both have 1 in the column $k$ . Hence,  $a_{ik} = 1$ and $a_{jk} = 1$ indicates that both actors participated in the event $k$. So, the total number of co-memberships for the two actors can be computed from the number of times that $a_{ik} = 1$ and $a_{jk} = 1$ where $k$ takes all possible values. The number of events with which both actors $i$ and $j$ are associated will vary from  0(if both have no affiliated events in common) to $h$(if both have all affiliated events in common).\\\\

Community detection is widely discussed topic in the social networking literature\footnote{Social networks are generally sparse networks. When the networks are dense, the community detection does not seem to be the wise option. The dense networks possess large number of inter-community edges which yields poor partitioning. For dense networks, discrete data analysis techniques are used.}. There is no universally accepted definition of community as the idea of community is pertinent to the underlying network. The general picture of community detection algorithm relies on the quality function which defines the quality of the cluster. The algorithm aims at either maximizing or minimizing(depends on the way quality function has been defined) cumulative quality of the network. Generally the quality function for a community is defined to be the difference between intra-community edges and inter-community edges. \\\\

There are different classes of community detection algorithms. Graph partitioning algorithms return two partitions of the network using techniques like max flow min cut, conductance, etc. Despite their scalability, these algorithms require the analyst to have some idea about the groups in the network beforehand. So they are not good for the exploration of the groups in the community. Similarly partition clustering algorithms, like k-means clustering, needs analyst conjecture about the existence of clusters. These algorithms also require the graph to be embedded in the metric space to quantify the notion of the distance. Spectral clustering algorithms reuqire eigenvalue decomposition of the network graph which is prohibitive for massive networks. Hierarchical partitioning techniques, comprising of agglomerative and divisive partitioning methods, are good for the exploratory analysis. Agglomerative clustering techniques are computationally expensive. 


\section{Problem Description}
In this project, we aim to probe the groups of users within goodreads based on their reading interests. As stated earlier, goodreads is more than just a book reviewing website. Users and authors on goodreads can connect amongst themselves forming a rich social network. We do not want to observe the groups/clusters within such a social network, which already exists in goodreads, since this network may not necessarily capture the reading interests of the users in it. We will use the information about the books read, the authors people are fans of and the group memberships to capture the ties amongst the users. \\\\

In this section, we only focus on the book read by two users. Let $U$ and $B$ be the set of users and the set of books on goodreads respectively. We will construct an undirected bipartite graph $G(V, E)$ using these two sets where $V ~=~ U \cup B$. An edge exists betweem a vertex $u_i \in U$ and a vertex $b_k \in B$ if a user $u_i$ has read book $b_k$.\\\\
We consider the rating given by a user $u_i$ to a book $b_k$ to assign weight to the edge between them. The weight to this edge plays an important role in the semantics of the networks. Consider a scenario wherein a book $b_k$ is read by both the users $u_i$ and $u_j$. Suppose user $u_i$ has liked the book and hence has positively rated the book whereas user $u_j$ has not liked the book and so has given a low rating to the book. If we do not take this fact into the account then these users might end up being placed in a same reading group. So as to prevent situation, we assign weight to the edges in $G$. Let $r_{ik}$ be the rating given by user $u_i$ to book $b_k$. Let $w \rightarrow E \times \{1, -1\}$ be the weight function.\\
$\forall (i, k) \in E$, 
\[
	w((i, k)) = \left\{\def\arraystretch{1.2}%
		\begin{array}{@{}c@{\quad}l@{}}
		1 & r_{ik} \geq \alpha\\
		-1 & r_{ik} < \alpha\\
		\end{array}\right.
\]
where $\alpha$ is some threshold which can be tuned during the experimentation.\\
A similar study can be conducted based on the author $a_k \in A$ or the group membership $g_k \in G$, for instance:\\
$\forall (i, k) \in F=U \cup G$, 
\[
	w((i, k)) = \left\{\def\arraystretch{1.2}%
		\begin{array}{@{}c@{\quad}l@{}}
		1 & u_i \in g_k\\
		0 & u_i \notin g_k\\
		\end{array}\right.
\]
\\\\
Let $\mathcal{M}$ be a $|U| \times |B|$ matrix which represents the underlying graph $G$. If there exists an edge between user $u_i$ and book $b_k$ then $\mathcal{M}_{ik}^{th}$ entry in the matrix is set to the weight of the corresponding edge otherwise the entry is set to zero. We obtain $\mathcal{U}$, matrix encoding the relationship amongst the users, using $\mathcal{M}$ by calculating $\mathcal{M}\mathcal{M}^{T}$. The graph encoded by $\mathcal{U}$ is the graph of the interest for finding the user groups. We propose to explore the interesting user groups by using graph partitioning algorithms like Girvan-Newmann algorithm.


\section{Underlying Assumptions}
\section{Data acquisition}

Goodreads data is not available online, we have to acquire all data through their APIs. Stanford students have already studied Goodreads platform by building a product recommendation. \cite{stanford:goodreads}. However, they have not published the data they acquired and we think that their data acquisition is wrongly implemented based on erroneous assumptions. Indeed, they acquired data through the \textit{book.shelves} api method. Given a \textit{user\_id} and a bookshelf name, they were able to query all the books a user may have put in this virtual bookshelf. The major issue is that goodreads do not list every user\_id. They then decided to query for user\_id randomly to query the books people have put to their public `reading' shelve. Finally, they only gather 4000 users and their `reading books'.

We have decided to query the data using other APIs, available at \cite{goodreads:api}:
\begin{itemize}
\item group.list - List groups for a given user
\item group.members - Return members of a particular group
\item group.show - Get info about a group
\item fanship.show - Show author fanship information
\item owned\_books.list - List books owned by a user
\item shelves.list - Get shelves owned by a user
\item user.show - Get shelves owned by a user
\item user.followers - Get user's followers
\item user.following - Get people a user is following
\item user.friends - Get people a user is following
\end{itemize}

Here, we see we can add many kinds of information related to the network of a user:
\begin{itemize}
\item such as in Twitter, a user can follow other users, and can be followed
\item a user can take part in reading groups
\item a user can be fan of an author
\item we have all books stored in all shelves of a user
\item we have all friends of a user
\end{itemize}

Goodreads have 30 million users which may be too large for our study, but the goal is to gather an acceptable amount of data. Goodreads provide the top user in certain categories such as the top 50 active users, top 50 readers, top 50 most popular reviewers well as the best reviews. These statistics are computed for the last week, last month, last 12 months and all the time for each country( as well as worlwide).
Based on the top users, we have a list of user\_id from which we can query the data. On the other hand, for each user, we will store the books read and stored on the shelves, the authors the user is fan of and the groups the user belongs to.\
Finally, we only can query a user data if the profile is public. Based on our first study, most profile are public and thus should not raise an issue. Even so, we will store the information that a user profile is private.


\section{Project Objectives}

Based on the large information we can have on a user, we can generate several kinds of network:
\begin{itemize}
\item a Twitter network based on the following/followers relation
\item a Group network, as same members of a group are linked
\item a Author network, as being fan of the same author strenghen the bound between two users
\item a Book network, as having read the same books show similar tastes in literature
\item a Friend network, already implemented in goodreads
\end{itemize}

\section{Literature review}
\label{sec:literature_review}
We compare n methods for the clustering of our dataset. We give a brief summary of the different clustering methods and state if these methods will be scalable to our own dataset.

Quantitatively, clustering aims at assigning each data point to a cluster.



\subsection{Hierarchical Clustering}
Hierarchical clustering builds a hierarchy of clusters, Either it is built \emph{bottom up}, as we start with the same numbers of clusters and data points, and we try to group clusters with each other. The \emph{top down} us the opposite: we start with a unique cluster that we are going to split recursevely.\\

Complexity is very high ($\Theta$($n^3$)), and thus is not pertinent to big datasets, even if heuristics lower the complexity to ($\Theta$($n^2$).


\subsection{K-Means Clustering}

K-means clustering aims at computing k clusters from that will minimize the distance from the data points to the cluster, such as we will split n data points into k groups. It is a centroid-based clustering, and does not apply only to graphs.
The most common application of k-means clustering is the iterative algorithm named Lloyd's algorithm.
The major issue is that we have to set in advance the number of clusters we want to 

\begin{enumerate}
\item Initalize (randomly preferably) the center of the k clusters
\item For each point, assign to it the closest cluster
\item Compute the new position of every cluster as the center of all data points assigned to this cluster
\item Repeat 2 and 3 until the clusters do not move (Relative to a $\epsilon$ for instance)
\end{enumerate}


% http://networkx.github.io/documentation/networkx-1.9.1/reference/generated/networkx.algorithms.cluster.clustering.html?highlight=clustering#networkx.algorithms.cluster.clustering

% http://jponnela.com/web_documents/a9.pdf     network x clustering algo

% Girvan-Newman algo
% https://en.wikipedia.org/wiki/Girvan%E2%80%93Newman_algorithm

% Graph tool algo
% http://graph-tool.skewed.de/static/doc/clustering.html

% Clustering Stanford
% http://web.stanford.edu/class/cs345a/slides/12-clustering.pdf

% Stanford goodreads
% http://cs229.stanford.edu/proj2008/IsaacsonSebastian-GoodReadsRecommendations.pdf


\section{Proposed Contributions}
\section{Success Measures}

Our entire work depends on acquiring the data in a short amount of time. We consider we validate this part if we manage to gather at least one million users with all their features (friends, books owned, followers, users following\dots) stored.\\
Then, we will implement a clustering algorithm presented in section \ref{sec:literature_review} that we will try to apply.


\section{Project Plan}

\subsection{Data acquisition}
\subsection{Clustering implementation}
\subsection{Test}
\subsection{Report redaction}


\section{Deliverables}


\bibliographystyle{abbrv}
\bibliography{references}
\end{document}
